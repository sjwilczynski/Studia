
\documentclass[12pt,wide]{mwart}

\usepackage[utf8]{inputenc}  
\usepackage[OT4,plmath]{polski}
\usepackage{graphicx}    
\usepackage{caption}
\usepackage{subcaption}
\usepackage{epstopdf}
\usepackage{amsmath,amssymb,amsfonts,amsthm,mathtools}
\usepackage{bbm}               % \mathbbm{N} - zbior liczb naturalnych
\usepackage{hyperref}
\usepackage{url}
\usepackage{comment}           % Pakiet komentarzy wieloliniowych

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\date{Wrocław, \today}
\title{\LARGE\textbf{Pracownia z analizy numerycznej}\\ Sprawozdanie do zadania \textbf{P.2.18}}
\author{Stanisław Wilczyński\thanks{\textit{E-mail}: \texttt{opos1@onet.eu}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% środowisko do pisania twierdzeñ.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{tw}{Twierdzenie}
\newtheorem{defin}{Definicja}
\newtheorem{alg}{Algorytm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\langle  i \rangle \left<
%wykresy wielomianow

\begin{document}
\maketitle                % Utworzenie tytułu.
\thispagestyle{empty}     % Nie numerujemy pierwszej strony.
\tableofcontents          % Spis treści

\section{Wstęp}

Ortogonalizacja układu wielomianów jest niezwykle ważna ze względu na wykorzystywanie baz ortogonalnych w rozwiązywaniu problemu aproksymacji funkcji względem normy średniokwadratowej, czyli znajdowaniu wielomianu optymalnego(najlepiej przybliżającego) daną funkcję. Zortogonalizowanie niewielkiej bazy nie powinno być problem dla jakiegokolwiek studenta mającego do czynienia z algebrą, jednakże w przypadku aproksymacji z dużą dokładnością potrzebne są wielomiany wysokich stopni. Powoduje to oczywiście brak możliwości ręcznego wyliczenia bazy ortogonalnej. Oczywiście, w takim wypadku trzeba się wspomóc komputer. W tym sprawozdaniu przedstawimy dwie metody tworzenia bazy ortogonalnej na zbiorze dyskretnym oraz omówimy ich numeryczne zalety i wady.

\section{Podstawowe pojęcia}
W tym rozdziale przedstawimy podstawowe pojęcia niezbędne do zrozumienia procesu ortogonalizacji. Poniższe definicje zostały wzięte z \cite{JMJ}.

\begin{defin}{Iloczyn skalarny}\\
Na przestrzeni liniowej $V$ definiujemy funkcję zwaną iloczynem skalarnym, która każdej parze elementów $f,g \in V$ przyporządkowuje liczbę rzeczywistą $\langle f,g \rangle$ i spełnia następujące warunki:
\begin{itemize}
	\item $\langle f,f \rangle \geq 0$; $\langle f,f \rangle = 0$ wtedy i tylko wtedy, gdy $f$ = 0
	\item $\langle f,g \rangle = \langle g,f \rangle$
	\item $\langle \alpha f + \beta g ,h \rangle = \alpha\langle f,h \rangle + \beta\langle g,h \rangle$\\
	dla dowolnych $f,g,h \in V$ i $\alpha,\beta \in \mathbbm{R}$.
\end{itemize} 
\end{defin}

\begin{defin}{Przestrzeń unitarna}\\
Przestrzenią unitarną nazywamy przestrzeń liniową wyposażoną w iloczyn skalarny.
\end{defin}

\begin{defin}{Ortogonalność}\\
Mówimy,że w przestrzeni unitarnej $V$ elementy $f,g$ są ortogonalne, jeśli $\langle f,g \rangle = 0$. 
\end{defin}

\begin{defin}{Przestrzeń $l^2_{p,r}$}\\
Przestrzeń unitarna $l^2_{p,r}$ to przestrzeń funkcji, których dziedziną jest $\mathbbm{R}$, a przeciwdziedziną podzbiór $\mathbbm{R}$ z wyróżnionymi: układem punktów $\{x_0,x_1,\ldots,x_r\}$ oraz nieujemną funkcją p zwaną wagową. W tej przestrzeni definiujemy iloczyn skalarny:
\begin{eqnarray*}
	\langle  f,g \rangle = \sum^r_{i=0} f(x_i)g(x_i)p(x_i) = 0
\end{eqnarray*}\\
Na tej właśnie przestrzeni będziemy testować metody ortogonalizacji wielomianów.
\end{defin}

\begin{defin}{Ciąg wielomianów ortogonalnych}\\
Ciąg $P_0,P_1,\ldots,P_n$, gdzie $P_k$ jest wielomianem stopnia dokładnie $k$ nazywamy ciągiem wielomianów ortogonalnych na zbiorze dyskretnym $\{x_0,x_1,\ldots,x_r\}$, z wagą $p$, jeśli tworzą one układ ortogonalny w przestrzeni $l^2_{p,r}$,tzn.
$$
	\langle  P_k,P_l \rangle = 0
$$
dla $k \neq l$, $k$,$l = 0,1,\ldots,n ( n \leq r)$, gdzie $p(x_i), i = 1,2,...,r$ są danymi liczbami stałego znaku.\\
Na danej przestrzeni ciąg wielomianów ortogonalnych jest wyznaczony jednoznacznie z dokładnością do mnożników liczbowych(\cite[strona 93]{JMJ})
\end{defin}

\begin{defin}{Wielomiany Czebyszewa}\\
Wielomianami Czebyszewa nazywamy ciąg wielomianów $\{T_k\}$, gdzie 
$$
	T_k(x) = \cos(k \cdot \arccos x)
$$
Wielomiany te spełniają zależność rekurencyjną
\begin{eqnarray*}
T_k(x) &=& 2xT_{k-1}(x) - T_{k-2}(x), \ \ k = 2,3,\ldots \\
T_1(x) &=& x\\
T_0(x) &=& 1
\end{eqnarray*}
\end{defin}
W \cite[strony 98-99]{JMJ} podane są 2 ważne własności wielomianów Czebyszewa:
\begin{itemize}
\item $T_k$ ($k \neq 0$) ma zera $z_j$ jednokrotne rzeczywiste, leżące w przedziale $(-1,1)$ i równe
$$
	z_j = \cos\frac{(2j-1)\pi}{2k}, \ \  j = 1,2,\ldots,k
$$
\item $T_k$ ($k \neq 0$) ma k+1 punktów ekstremalnych $y_j$:
$$
y_j = \cos \frac{j\pi}{k}, \ \ j = 0,1,\ldots,k
$$
\end{itemize}
W \cite{Czeb} można również znaleźć, że:
\begin{itemize}
\item $T_0,\ldots,T_N$ tworzą układ ortogonalny w przestrzeni $l^2_{p,N}$, gdzie funkcja wagowa jest stale równa 1, a zbiór punktów to pierwiastki $T_{N+1}$.
\item $T_0,\ldots,T_N$ tworzą układ ortogonalny w przestrzeni $l^2_{p,N}$, gdzie zbiór punktów $\{y_i\}_0^N$ to ekstrema $T_{N}$ oraz $p(y_i) = 1$ dla $i \neq 0,N$ oraz $p(y_0) = p(y_N) = \frac{1}{2}$.
\end{itemize}


\section{Ortogonalizacja Grama-Schmidta}
\subsection{Opis metody}
Mając dany układ liniowo niezależnych elementów przestrzeni unitarnej $f_1$,$f_2$,\ldots$f_n$ konstruujemy metodą ortogonalizacji Grama-Schmidta w sposób następujący:
\begin{eqnarray*}
	g_1 &=& f_1 \\
	g_i &=& f_i - \sum^{i-1}_{j=1} \frac{\langle f_i,g_j\rangle}{\langle g_j,g_j\rangle}g_j,  \ \  i = 2,3,\ldots,n
\end{eqnarray*}

\subsection{Dowód poprawności}\footnote{Dowód zaczerpnięty z \cite[strona 90]{JMJ}} 
Pokażemy indukcyjnie, że otrzymany układ jest ortogonalny oraz, że każdy z wektorów $g_i$ jest kombinacją liniową $f_1$,\ldots,$f_i$. Dla $i=1$ jest oczywiste. Załóżmy, że dla $i \geq 2$ własności te ma układ $g_1$,\ldots,$g_{i-1}$. Dla dowolnego $ k \leq i-1$ mamy:
\begin{eqnarray*}
	\langle g_i,g_k\rangle = \langle f_i,g_k\rangle - \sum^{i-1}_{j=1} \frac{\langle f_i,g_j\rangle}{\langle g_j,g_j\rangle}\langle g_j,g_k\rangle
\end{eqnarray*}
Z założenia indukcyjnego $\langle g_j,g_k\rangle = 0$ dla $j\neq k, j,k \leq i-1$. Stąd:
\begin{eqnarray*}
	\langle g_i,g_k\rangle = \langle f_i,g_k\rangle - \frac{\langle f_i,g_k\rangle}{\langle g_k,g_k\rangle}\langle g_k,g_k\rangle = 0
\end{eqnarray*}
Skonstruowany w ten sposób element $g_i$ jest ortogonalny do poprzednio wyznaczonych $g_1$,\ldots,$g_{i-1}$ oraz $g_i$ jest niezerową kombinacją liniową $f_i$, $g_1$,\ldots,$g_{i-1}$. W takim razie z założenia indukcyjnego wynika, że $g_i$ jest kombinacją liniową $f_1$,\ldots,$f_i$ a $f_i$ występuje ze współczynnikiem 1. Ponieważ układ \{$f_n$\} jest liniowo niezależny to elementy układu {$g_n$} są dobrze określone, a przestrzenie rozpięte przez te układy są identyczne.

\section{Ortogonalizacja - reguła trójczłonowa}
 
\subsection{Opis metody}
Ciąg wielomianów $\{P_n\}^r_{n=0}$ zdefiniowanych rekurencyjnie:
$$
	P_n(x) = (x-a_n)P_{n-1} - b_n P_{n-2}
$$
dla $(n \geq 2)$, gdzie $P_0 = 1, P_1 = x - a_1$ oraz:
$$
	a_n = \frac{\langle xP_{n-1},P_{n-1} \rangle}{\langle P_{n-1},P_{n-1} \rangle} \ \ \ (dla \ n \geq 1)
$$
$$
	b_n = \frac{\langle P_{n-1},P_{n-1} \rangle}{\langle P_{n-2},P_{n-2} \rangle} \ \ \ \ (dla \ n \geq 2)
$$
jest ciągiem wielomianów ortogonalnych w przestrzeni $l^2_{p,r}$.
\subsection{Dowód poprawności}\footnote{Dowód zaczerpnięty z \cite[strona 365]{Kin}} 
Łatwo zauważyć,że $P_n$ jest stopnia dokładnie $n$,a więc jest niezerowy. W takim razie współczynniki $a_n$ i $b_n$ są dobrze określone. Pokażemy przez indukcję, że dla $0 \leq n \leq r$ $\langle P_n,P_i \rangle = 0$ dla $i = 0,1,\ldots,n-1$ dla $n=1$ mamy:
$$
 \langle P_1,P_0 \rangle = \langle (x-a_1)P_0,P_0 \rangle = \langle xP_0,P_0 \rangle - a_1\langle P_0,P_0 \rangle = 0 
$$
Załóżmy tezę indukcyjną dla indeksu $n-1$, gdzie $n \geq 2$. Wtedy
\begin{eqnarray*}
\langle P_n,P_{n-1} \rangle &=& \langle xP_{n-1},P_{n-1} \rangle - a_n\langle P_{n-1},P_{n-1} \rangle - b_n\langle P_{n-2},P_{n-1} \rangle = 0\\
\langle P_n,P_{n-2} \rangle &=& \langle xP_{n-1},P_{n-2} \rangle - a_n\langle P_{n-1},P_{n-2} \rangle - b_n\langle P_{n-2},P_{n-2} \rangle=\\&=& \langle P_{n-1},xP_{n-2} \rangle - \langle P_{n-1},P_{n-1} \rangle= \\
&=& \langle P_{n-1},xP_{n-2} - P_{n-1} \rangle = \langle P_{n-1},a_{n-1}P_{n-2} + b_{n-1}P_{n-3} \rangle = 0
\end{eqnarray*}
Dla $i = 0,1,\ldots,n-3$ mamy
\begin{eqnarray*}
\langle P_n,P_i \rangle &=& \langle xP_{n-1},P_i \rangle - a_n\langle P_{n-1},P_i \rangle - b_n\langle P_{n-2},P_i \rangle =\\ &=& \langle P_{n-1},xP_i \rangle = \\ &=& \langle P_{n-1},P_{i+1} + a_{i+1}P_i + b_{i+1}P_{i-1} \rangle = 0 
\end{eqnarray*}


\section{Porównanie metod}
%uwaga na kumulacje bledu rt - JMJ s.108
W obu metodach do obliczenia bazy ortogonalnej potrzeba wykonania dużej liczby operacji arytmetycznych, ale ich dość spora część jest skupiona w obliczaniu iloczynów skalarnych. W przypadku metody Grama-Schmidta liczba obliczonych iloczynów skalarnych jest $O(n^2)$, natomiast w przypadku korzystania z reguły trójczłonowej liczba ta jest $O(n)$. Co za tym idzie, spodziewamy się, że obliczanie z wykorzystaniem reguły trójczłonowej będzie obarczone mniejszym błędem niż korzystanie z metody Grama-Schmidta.\\

Doświadczenie przeprowadzimy na trzech układach $n$ punktów dla $n = 5,10,20,30,40,50,60$:
\begin{enumerate}
    \item ekstrema $n-1$-szego wielomianu Czebyszewa
    \item pierwiastki $n$-tego wielomianu Czebyszewa \footnote{Z własności wielomianów Czebyszewa spodziewamy się, że po zoortogonalizowaniu na tych dwóch układach punktów dostaniemy wielomiany Czebyszewa ponieważ na naszej przestrzeni ciąg wielomianów jest wyznaczony jednoznacznie z dokładnością do mnożników liczbowych a o wielomiany Czebyszewa są ortogonalne.}
    \item punkty równoodłegłe na przedziale $[-1,1]$, tj. $\{x_i\}_0^{n-1}$, gdzie $x_i = -1 + \frac{2i}{n-1}$\footnote{tutaj otrzymamy wielomiany Grama \cite[strona 97]{JMJ}.}\\
\end{enumerate}    
Jako wyznacznik jakości metody weźmiemy średni błąd sumaryczny, tzn. dla otrzymanego układu wektorów obliczmy iloczyn skalarny każdej z ${n \choose 2}$ par, weźmiemy ich wartości bezwzględne, zsumujemy i podzielimy przez liczbę par. Poniżej zamieszczamy tabelę wyników otrzymanych z obliczeń wykonanych za pomocą załączonego programu \textit{ortogonalizacja.jl}\footnote{Odpowiednie wyjaśnienia dotyczące sposoby działania programu są zawarte w nim samym w komentarzach.}\\

 \begin{tabular}{|c|c|c|c|c|c|c|}
 \hline 
 n & BłądRT1 & BłądGS1 & BłądRT2 & BłądGS2 & BłądRT3 & BłądGS3 \\ 
 \hline 
 $5$ & $4\cdot 10^{-17}$ & $4\cdot 10^{-17}$ & $9\cdot 10^{-17}$ & $7\cdot 10^{-17}$ & $2\cdot 10^{-17}$ & $1\cdot 10^{-17}$ \\ 
 \hline 
 $10$ & $9\cdot 10^{-17}$ & $3\cdot 10^{-16}$ & $1\cdot 10^{-16}$ & $3\cdot 10^{-16}$ & $1\cdot 10^{-16}$ & $3\cdot 10^{-16}$ \\ 
 \hline 
 $20$ & $1\cdot 10^{-16}$ & $7\cdot 10^{-13}$ & $2\cdot 10^{-16}$ & $4\cdot 10^{-12}$ & $1\cdot 10^{-16}$ & $1\cdot 10^{-12}$ \\ 
 \hline 
 $30$ & $8\cdot 10^{-16}$ & $1\cdot 10^{-6}$ & $1\cdot 10^{-15}$ & $7\cdot 10^{-7}$ & $2\cdot 10^{-16}$ & $1\cdot 10^{-7}$ \\ 
 \hline 
 $40$ & $4\cdot 10^{-15}$ & $3\cdot 10^{-4}$ & $2\cdot 10^{-15}$ & $8\cdot 10^{-5}$ & $6\cdot 10^{-16}$ & $3\cdot 10^{-5}$ \\ 
 \hline 
 $50$ & $8\cdot 10^{-14}$ & $3\cdot 10^{-3}$ & $1\cdot 10^{-13}$ &$4\cdot 10^{-3}$ & $7\cdot 10^{-12}$ & $1\cdot 10^{-3}$ \\ 
 \hline 
 $60$ & $6\cdot 10^{-4}$ & $2\cdot 10^{-2}$ & $1\cdot 10^{-3}$ & $1\cdot 10^{-2}$ & $9\cdot 10^{0}$ & $1\cdot 10^{-2}$ \\ 
 \hline 
 $70$ & $1\cdot 10^{30}$ & $8\cdot 10^{-2}$ & $5\cdot 10^{27}$ & $8\cdot 10^{-2}$ & $8\cdot 10^{49}$ & $5\cdot 10^{-2}$ \\ 
 \hline 
 \end{tabular}\\
 
BłądRT dotyczy błędu przy zastosowaniu reguły trójczłonowej, BłądGS przy ortogonalizacji Grama-Schmidta natomiast indeks numer układu punktów, na którym wykonano obliczenia. W tabelce podajemy tylko pierwszą cyfrę znaczącą w celu zachowania przejrzystości prezentowanych danych. Zauważamy, że dla $n\leq 20$ błędy są bardzo małe a otrzymane przez nas wielomiany bardzo bliskie rzeczywistym układom wielomianów ortogonalnych(w załączonym programie jest wykres $T_9$ oraz wielomianów mu odpowiadających, które otrzymaliśmy z ortogonalizacji). Co więcej, widzimy, że dla $n \leq 50$ metoda używająca reguły trójczłonowej wciąż jest bardzo dokładna w przeciwieństwie do ortogonalizacji Grama-Schmidta. Niestety, dla większych $n$ widzimy, że błąd w regule trójczłonowej eksploduje i dla $ n = 70$ jest dla pierwszego układu punktów rzędu $10^{30}$. Skąd tak ogromny skok wartości?\\

Tak jak się spodziewaliśmy dla $n \leq 50$ dokładność metody używającej reguły trójczłonowej jest dużo lepsza niż tej dla Grama-Schmidta, gdyż potrzebuje obliczenia zdecydowanie mniejszej liczby iloczynów skalarnych. Dla większych $n$ przestaje mieć to znaczenie ze względu na kumulację błędu, która powstaje z powodu rekurencyjnej definicji reguły trójczłonowej(kolejne współczynniki w rekurencji korzystają \underline{tylko} z iloczynów skalarnych par wielomianów na wcześniejszych krokach - a te zostały obliczone z pewnym błędem). W metodzie Grama-Schmidta problem ten nie ma takiego znaczenia, gdyż kolejne wyniki zależą nie tylko od wyników poprzednich obliczeń, np. $\langle f_i,g_j\rangle$ na każdym kroku algorytmu. Wyciągamy, więc wniosek, że metoda z ortogonalizacją Grama-Schmidta jest numerycznie stabilna w przeciwieństwie do metody używającej reguły trójczłonowej.
 
	
\section{Podsumowanie}

Z przeprowadzonej analizy wynika, że metoda korzystająca z reguły trójczłonowej dla małych układów punktów daje nam układ wielomianów bardzo bliski prawdziwemu układowi ortogonalnemu. Niestety, dla dużych układów jest całkowicie nieskuteczna. Wtedy lepiej jest stosować bardziej kosztowną obliczeniowo metodę Grama-Schmidta. Poza tym bardzo łatwo poprawić dokładność tej metody. Wystarczy zortogonalizować tą metodą otrzymany układ i ewentualnie wykonać ten krok ponownie(aż do otrzymania zadowalającego rezultatu). Niestety, ta metoda także nie poradzi sobie z za dużymi układami punktów ze względu na dużą złożoność obliczeniową ortogonalizacji tym sposobem($O(n^3)$). Ostatecznie stwierdzamy, że metoda korzystająca z reguły trójczłonowej jest szybka i dokładna dla niedużych układów punktów, natomiast przy użyciu metody z ortogonalizacją Grama-Schmidta można znaleźć większe układy ortogonalne oraz łatwo poprawić dokładność otrzymanego wyniku, jednak jest to metoda kosztowna obliczeniowo. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{thebibliography}{9}
\itemsep2pt
\bibitem{JMJ} J. i M Jankowscy, Przegląd metod numerycznych część 1,
             Wydawnictwo Naukowo-Techniczne, Warszawa, 1988.
             
						
\bibitem{Kin} D.Kincaid, W.Cheney, Numerical Analysis. Mathematics of scientific computing, Brooks/Cole Publishing Company,Pacific Groove California, 1991.

\bibitem{Czeb} Bogdan Mihaila, Numerical Approximations Using Chebyshev Polynomial Expansions, Mathematics Department, Coastal Carolina University, Conway,1999. \url{http://cds.cern.ch/record/375960/files/9901005.pdf}
							

							
\end{thebibliography}
\end{document}
