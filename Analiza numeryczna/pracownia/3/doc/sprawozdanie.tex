
\documentclass[12pt,wide]{mwart}

\usepackage[utf8]{inputenc}  
\usepackage[OT4,plmath]{polski}
\usepackage{graphicx}    
\usepackage{caption}
\usepackage{subcaption}
\usepackage{epstopdf}
\usepackage{amsmath,amssymb,amsfonts,amsthm,mathtools}
\usepackage{bbm}               % \mathbbm{N} - zbior liczb naturalnych
\usepackage{hyperref}
\usepackage{url}
\usepackage{comment}           % Pakiet komentarzy wieloliniowych

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\date{Wrocław, \today}
\title{\LARGE\textbf{Pracownia z analizy numerycznej}\\ Sprawozdanie do zadania \textbf{P.3.3}}
\author{Stanisław Wilczyński\thanks{\textit{E-mail}: \texttt{opos1@onet.eu}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% środowisko do pisania twierdzeñ.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{tw}{Twierdzenie}
\newtheorem{defin}{Definicja}
\newtheorem{alg}{Algorytm}
\newtheorem{lem}{Lemat}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\langle  i \rangle \left<
%wykresy wielomianow

\begin{document}
\maketitle                % Utworzenie tytułu.
\thispagestyle{empty}     % Nie numerujemy pierwszej strony.
\tableofcontents          % Spis treści

\section{Wstęp}
Wielomiany ortogonalne są niezwykle ważne ze względu na ich szerokie zastosowania w metodach numerycznych. Ich szczególnie ciekawym rodzajem są powszechnie znane wielomiany Czebyszewa. Wykorzystuje się je nie tylko w aproksymacji średniokwadratowej, ale również w aproksymacji jednostajnej czy przy obliczaniu całek. Kwadratura Gaussa-Czebyszewa jest przecież kwadraturą bardzo wysokiego rzędu, a jest to nic innego jak całka z wielomianu interpolacyjnego Czebyszewa. Tematem poniższej pracy będzie zastosowanie wielomianów interpolacyjnych Czebyszewa w aproksymacji jednostajnej funkcji oraz próba poprawienia wyniku aproksymacji przez niewielkie modyfikacje tych wielomianów.


\section{Definicje oraz twierdzenia}
W tym rozdziale przedstawimy podstawowe pojęcia niezbędne do zrozumienia tematu niniejszego sprawozdania. Większość poniższych definicji zostało wziętych z \cite{JMJ}.

\begin{defin}{Iloczyn skalarny}\\
Na przestrzeni liniowej $V$ definiujemy funkcję zwaną iloczynem skalarnym, która każdej parze elementów $f,g \in V$ przyporządkowuje liczbę rzeczywistą $\langle f,g \rangle$ i spełnia następujące warunki:
\begin{itemize}
	\item $\langle f,f \rangle \geq 0$; $\langle f,f \rangle = 0$ wtedy i tylko wtedy, gdy $f$ = 0
	\item $\langle f,g \rangle = \langle g,f \rangle$
	\item $\langle \alpha f + \beta g ,h \rangle = \alpha\langle f,h \rangle + \beta\langle g,h \rangle$\\
	dla dowolnych $f,g,h \in V$ i $\alpha,\beta \in \mathbbm{R}$.
\end{itemize} 
\end{defin}

\begin{defin}{Przestrzeń unitarna}\\
Przestrzenią unitarną nazywamy przestrzeń liniową wyposażoną w iloczyn skalarny.
\end{defin}

\begin{defin}{Ortogonalność}\\
Mówimy, że w przestrzeni unitarnej $V$ elementy $f,g$ są ortogonalne, jeśli $\langle f,g \rangle = 0$. 
\end{defin}

\begin{defin}{Przestrzeń $l^2_{p,r}$}\\
Przestrzeń unitarna $l^2_{p,r}$ to przestrzeń funkcji, których dziedziną jest $\mathbbm{R}$, a przeciwdziedziną podzbiór $\mathbbm{R}$ z iloczynem skalarnym określonym wzorem:
\begin{eqnarray*}
	\langle  f,g \rangle = \sum^r_{i=0} f(x_i)g(x_i)p(x_i),
\end{eqnarray*}
gdzie $\{x_0,x_1,\ldots,x_r\}$ jest wyróżnionym zbiorem punktów, a p nieujemną funkcją zwaną funkcją wagową.
\end{defin}

\begin{defin}{Norma}\\
Normą średniokwadratową w $l^2_{p,r}$ funkcji $f$ nazywamy wartość $||f||_2 = \sqrt{\langle f,f \rangle}$. Normą jednostajną w $l^2_{p,r}$ nazywamy $||f||_\infty = \sup_{x \in X} |f(x)|$,gdzie $X$ jest wyróżnionym zbiorem punktów naszej przestrzeni.
\end{defin}

\begin{defin}{Wielomian optymalny}\\
Niech $\pi_n$ oznacza przestrzeń wielomianów stopnia nie większego niż n. n-tym wielomianem optymalnym względem pewnej normy $|| \cdot ||$ nazywamy wielomian $w_n \in \pi_n$ spełniający
\begin{eqnarray*}
||f-w_n|| = inf_{p \in \pi_n} ||f -p||.
\end{eqnarray*}
\end{defin}

\begin{defin}{Ciąg wielomianów ortogonalnych}\\
Ciąg $P_0,P_1,\ldots,P_n$, gdzie $P_k$ jest wielomianem stopnia dokładnie $k$ nazywamy ciągiem wielomianów ortogonalnych na zbiorze dyskretnym $\{x_0,x_1,\ldots,x_r\}$, z wagą $p$, jeśli tworzą one układ ortogonalny w przestrzeni $l^2_{p,r}$,tzn.
$$
	\langle  P_k,P_l \rangle = 0
$$
dla $k \neq l$, $k$,$l = 0,1,\ldots,n ( n \leq r)$.\\
Na danej przestrzeni ciąg wielomianów ortogonalnych jest wyznaczony jednoznacznie z dokładnością do mnożników liczbowych(\cite[strona 93]{JMJ})
\end{defin}

Potrzebne będą również dwa twierdzenia o wielomianach optymalnych:\\
\begin{tw}{(o n-tym wielomianie optymalny względem normy średniokwadratowej)\footnote{dowód tego twierdzenia można znaleźć w \cite[strona 91]{Bj}}}\\
Jeśli $\{P_k\}_{k=0}^n$ jest ciągiem wielomianów ortogonalnych to dla dowolnej funkcji ciągłej $f:[a,b] \rightarrow \mathbbm{R}$ n-ty wielomian optymalny w sensie normy średniokwadratowej jest jedyny i wyraża się wzorem:
\begin{eqnarray*}
w_n = \sum_{k=0}^n \frac{\langle f,P_k \rangle}{\langle P_k,P_k \rangle} \cdot P_k.
\end{eqnarray*}
\end{tw}

\begin{tw}{(Czebyszewa o alternansie){\footnote{\cite[strona 122]{Bj}}}}\\
Wielomian $w_n$ jest n-tym wielomianem optymalnym względem normy jednostajnej dla funkcji ciągłej $f:[a,b] \rightarrow \mathbbm{R}$ wtedy i tylko wtedy, gdy istnieje alternans, czyli zbiór $n+2$-punktowy $\{x_0,x_1,\ldots,x_{n+1}\} \subset [a,b]$ o własnościach: 
\begin{enumerate}
\item $e_n(x_k) = -e_n(x_{k-1})$ dla $k = 1,2,\ldots,n+1$
\item $|e_n(x_k)| = ||e_n||_\infty$ dla $k = 0,1,2,\ldots,n+1$,
\end{enumerate}
gdzie $e_n = f - w_n$.
\end{tw}

\subsection{Wielomiany Czebyszewa}
\begin{defin}{Wielomiany Czebyszewa}\\
Wielomianami Czebyszewa nazywamy ciąg wielomianów $\{T_k\}$, gdzie 
$$
	T_k(x) = \cos(k \cdot \arccos x)
$$
Wielomiany te spełniają zależność rekurencyjną
\begin{eqnarray*}
T_k(x) &=& 2xT_{k-1}(x) - T_{k-2}(x), \ \ k = 2,3,\ldots \\
T_1(x) &=& x\\
T_0(x) &=& 1
\end{eqnarray*}
\end{defin}

W \cite[strony 98-99]{JMJ} podane są dwie ważne własności wielomianów Czebyszewa:
\begin{itemize}
\item $T_k$ ($k \neq 0$) ma zera $z_j$ jednokrotne rzeczywiste, leżące w przedziale $(-1,1)$ i równe
$$
	t_{k,j} = \cos\frac{(2j-1)\pi}{2k}, \ \  j = 1,2,\ldots,k
$$
\item $T_k$ ($k \neq 0$) ma k+1 punktów ekstremalnych $u_j$:
$$
u_{k,j} = \cos \frac{j\pi}{k}, \ \ j = 0,1,\ldots,k.
$$
Co więcej $T_k(u_{k,j}) = (-1)^j$.
\end{itemize}

Pokażemy kilka przydatnych twierdzeń o wielomianach Czebyszewa:
\begin{lem}
Dla każdych $n,k,j \in \mathbbm{N}$ zachodzi $T_k(u_{n,j}) = T_j(u_{n,k})$.
\end{lem}
\begin{proof}
Weźmy dowolne $n,k,j \in \mathbbm{N}$. Wtedy 
$$
T_k(u_{n_j}) = \cos(k\cdot \frac{j}{n}\pi) = \cos(j\cdot \frac{k}{n}\pi) = T_j(u_{n,k})
$$
\end{proof}
\begin{tw}
$T_0,\ldots,T_N$ tworzą układ ortogonalny w przestrzeni $l^2_{p,N}$, gdzie funkcja wagowa jest stale równa 1, a zbiór punktów to pierwiastki $T_{N+1}$. Ponadto $\langle T_n,T_n \rangle = \frac{N+1}{2}$ dla $n \neq 0$ oraz $\langle T_0,T_0 \rangle = N+1.$  
\end{tw}

\begin{proof}
Do pokazania powyższego twierdzenia będzie potrzebny lemat zawarty w \cite{cos}:
\begin{lem}
Jeśli $\alpha,\theta \in \mathbbm{R}, \theta \neq 0$ oraz $N \in \mathbbm{N}$ mamy:
$$
\sum_{k=0}^N \cos(\alpha + k\theta) = \frac{\sin(\frac{N+1}{2}\theta)}{\sin(\frac{\theta}{2})}\cdot \cos(\alpha + \frac{N}{2}\theta).
$$
\end{lem}

Weźmy dowolne $n,m \in \{0,1,\ldots,N\}$. Wtedy
\begin{eqnarray*}
\langle T_n,T_m \rangle &=& \sum_{k=0}^N T_n(t_{N+1,k})\cdot T_m(t_{N+1,k}) =  \sum_{k=0}^N \cos\left(n \cdot \frac{2k+1}{2N+2}\pi\right)\cdot \cos\left(m \cdot \frac{2k+1}{2N+2}\pi\right) = \\&=& \frac{1}{2}\cdot \sum_{k=0}^N \left[\cos\left((n+m)\cdot \frac{2k+1}{2N+2}\pi\right) + \cos\left((n-m)\cdot \frac{2k+1}{2N+2}\pi\right)\right]
\end{eqnarray*}
W powyższej równości skorzystaliśmy z tożsamości trygonometrycznej: $$cos(x) \cdot cos(y) = \frac{1}{2}(cos(x+y)+cos(x-y)).$$ Oznaczmy $\theta_1 = (n+m)\frac{\pi}{N+1}$ wtedy $(n+m)\frac{2k+1}{2N+2}\pi = k\theta_1 + \frac{1}{2}\theta_1$.
Oznaczmy $\theta_2 = (n-m)\frac{\pi}{N+1}$ wtedy $(n-m)\frac{2k+1}{2N+2}\pi = k\theta_2 + \frac{1}{2}\theta_2$.
Używając tych oznaczeń dostajemy:
\begin{eqnarray}\label{rownosc}
\langle T_n,T_m \rangle = \frac{1}{2} \cdot \sum_{k=0}^N \left[\cos(k\theta_1 + \frac{1}{2}\theta_1) + \cos(k\theta_2 + \frac{1}{2}\theta_2)\right] 
\end{eqnarray}
Jeśli $n \neq m$ z lematu 2. otrzymujemy:
\begin{eqnarray*}
\langle T_n,T_m \rangle &=& \frac{1}{2} \cdot \left[ \frac{\sin((N+1)/2 \cdot \theta_1)}{\sin(\theta_1 /2)}\cdot \cos(\theta_1 /2 + N\theta_1 /2)\right]\\ &+& \frac{1}{2} \cdot \left[\frac{\sin((N+1)/2 \cdot \theta_2)}{\sin(\theta_2 /2)}\cdot \cos(\theta_2 /2 + N\theta_2 /2) \right] =\\ 
&=& \frac{1}{2} \cdot \left[\frac{\sin((N+1)/2 \cdot \theta_1)}{\sin(\theta_1 /2)}\cdot \cos((N+1)\theta_1 /2) + \frac{\sin((N+1)/2 \cdot \theta_2)}{\sin(\theta_2 /2)}\cdot \cos((N+1)\theta_2 /2) \right]
\end{eqnarray*}
Zauważmy, że
\begin{eqnarray*}
\sin((N+1)/2 \cdot \theta_1) \cdot \cos((N+1)\theta_1 /2) &=& \frac{1}{2} \sin((N+1) \cdot \theta_1 =\\ &=& \sin((n+m)\pi) = 0.
\end{eqnarray*}
Analogicznie $ \sin((N+1)/2 \cdot \theta_2) \cdot \cos((N+1)\theta_2 /2) = 0$. Otrzymujemy, więc $\langle T_n,T_m \rangle = 0$ dla $n \neq m$.
Dla $n=m$ podstawiając do \ref{rownosc} dostajemy:
\begin{eqnarray*}
\langle T_n,T_n \rangle &=&  \frac{1}{2} \cdot \sum_{k=0}^N [\cos(k\theta_1 + \frac{1}{2}\theta_1) + \cos(0)] = \\ &=& \frac{N+1}{2} + \frac{1}{2} \cdot \sum_{k=0}^N \cos(k\theta_1 + \frac{1}{2}\theta_1)   
\end{eqnarray*}
Jeśli $2n \neq 0$ korzystamy z lematu 2. i podobnie jak poprzednio otrzymujemy $\sum_{k=0}^N \cos(k\theta_1 + \frac{1}{2}\theta_1) = 0$, a więc dla $n \neq 0$ mamy $\langle T_n,T_n \rangle = \frac{N+1}{2}$. Natomiast dla $ n=0$
\begin{eqnarray*}
\frac{1}{2} \cdot \sum_{k=0}^N \cos(k\theta_1 + \frac{1}{2}\theta_1) = \frac{1}{2} \cdot \sum_{k=0}^N \cos(0) = \frac{N+1}{2}.
\end{eqnarray*}
W takim razie $\langle T_0,T_0 \rangle = N+1$
\end{proof}

\begin{tw} $T_0,\ldots,T_N$ tworzą układ ortogonalny w przestrzeni $l^2_{p,N}$, gdzie zbiór punktów $\{u_{N,i}\}_0^N$ to ekstrema $T_{N}$ oraz $p(u_{N,i}) = 1$ dla $i \neq 0,N$ oraz $p(u_{N,0}) = p(u_{N,N}) = \frac{1}{2}$. Ponadto $\langle T_n,T_n \rangle = \frac{N}{2}$ dla $n \neq 0, n \neq N$ oraz $\langle T_0,T_0 \rangle = \langle T_N,T_N \rangle = N.$  
\end{tw}

\begin{proof}
Weźmy dowolne $n,m \in \{0,1,\ldots,N\}$. Wtedy
\begin{eqnarray*}
\langle T_n,T_m \rangle &=& \sum_{k=0}^N'' T_n(u_{N,k})\cdot T_m(u_{N,k}) =  \sum_{k=0}^N'' \cos\left(n \cdot \frac{k}{N}\pi\right)\cdot \cos\left(m \cdot \frac{k}{N}\pi\right) = \\&=& \frac{1}{2}\cdot \sum_{k=0}^N'' \left[\cos\left((n+m)\cdot \frac{k}{N}\pi\right) + \cos\left((n-m)\cdot \frac{k}{N}\pi\right)\right]
\end{eqnarray*}
W powyższej równości skorzystaliśmy z tożsamości trygonometrycznej: $$cos(x) \cdot cos(y) = \frac{1}{2}(cos(x+y)+cos(x-y)).$$Oznaczmy $\theta_1 = (n+m)\frac{\pi}{N}$ wtedy $(n+m)\frac{k}{N}\pi = k\theta_1.$ Oznaczmy $\theta_2 = (n-m)\frac{\pi}{N}$ wtedy $(n-m)\frac{k}{N}\pi = k\theta_2$.
Używając tych oznaczeń dostajemy:
\begin{eqnarray}\label{rownosc2}
\langle T_n,T_m \rangle = \frac{1}{2} \cdot \sum_{k=0}^N'' [\cos(k\theta_1) + \cos(k\theta_2)] 
\end{eqnarray}
Jeśli $n \neq 0$ i $m \neq 0$  z lematu 2. otrzymujemy:
\begin{eqnarray*}
\sum_{k=0}^N \cos(k\theta_1) &=& \frac{\sin((N+1)/2 \cdot \theta_1)}{\sin(\theta_1 /2)}\cdot \cos(N\theta_1 /2) =\\ &=&
\frac{\sin(N/2 \cdot \theta_1)}{\sin(\theta_1 /2)} \cdot \cos(\theta_1 /2) \cdot \cos(N\theta_1 /2) + \frac{\sin(\theta_1 /2)}{\sin(\theta_1 /2)} \cdot \cos(N\theta_1 /2) \cdot \cos(N\theta_1 /2) = \\ &=&
\frac{1}{2}\cdot \frac{\sin(N\theta_1)}{\sin(\theta_1 /2)} \cdot \cos(\theta_1 /2) + \cos^2(N\theta_1 /2) =\\ &=&
\frac{1}{2}\left[\frac{\sin((n+m)\pi)}{\sin(\theta_1 /2)} \cdot \cos(\theta_1 /2) + \cos(N\theta_1)+1\right] = \frac{1}{2}\left[\cos(N\theta_1)+1\right]
\end{eqnarray*}
W powyższym rachunku wykorzystaliśmy tożsamości trygonometryczne:
\begin{itemize}
\item $\sin(x+y) = \sin(x)\cos(y)+\cos(x)\sin(y)$
\item $\cos(2x) = 2\cos^2(x)-1$
\end{itemize}
Podobnie, jeśli $n \neq m$ dostajemy $ \sum_{k=0}^N \cos(k\theta_2) = \frac{1}{2}[\cos(N\theta_2)+1].$Podstawiając do \ref{rownosc2} otrzymane wyniki dostajemy:
\begin{eqnarray*}
\langle T_n,T_m \rangle &=& \frac{1}{2} \cdot \sum_{k=0}^N \left[\cos(k\theta_1) + \cos(k\theta_2)\right] - \frac{1}{4} \left[\cos(0) + \cos(N\theta_1) + \cos(0) + \cos(N\theta_2)\right] =\\ &=& \frac{1}{4}\left[\cos(N\theta_1) + 1 - \cos(0) - \cos(N\theta_1) + \cos(N\theta_2) + 1 - \cos(0) - \cos(N\theta_2)\right] = 0.
\end{eqnarray*}
Z powyższego rachunku widzimy, że jeśli $\theta_1 \neq 0$(analogicznie dla $\theta_2$) to $$
\sum_{k=0}^N''\cos(k\theta_1) = 0.$$ W takim razie dla $n=m$ ale $n \neq 0,N$ dostajemy:$$ \langle T_n,T_n \rangle = \frac{1}{2} \cdot \sum_{k=0}^N''\cos(0) = \frac{N}{2}$$. Natomiast dla $n=m=0$ lub $n=m=N$ mamy $$ \langle T_n,T_n \rangle = \frac{1}{2} \cdot \sum_{k=0}^N''\cos(0)+\cos(0) = N$$
\end{proof}

\begin{tw}
Wielomian $I_n$ n-tego stopnia interpolujący funkcję $f$ w zerach $T_{n+1}$ ma postać:
$$
I_n(x) = \frac{2}{n+1} \cdot \sum_{k=0}^n'\left( \sum_{j=0}^n f(t_{n+1,j})T_k(t_{n+1,j})\right) T_k(x)
$$
\end{tw}

\begin{proof}
Zauważmy, że na zbiorze dyskretnym $n+1$ punktów wielomian $I_n$ jest optymalny względem normy średniokwadratowej, gdyż
\begin{eqnarray*}
||f - I_n||_\infty = \sup_{x \in \{t_{n+1,1},\ldots,t_{n+1,n+1}\}} |f(x) - I_n(x)| = 0,
\end{eqnarray*} a z definicji normy jednostajnej dla każdej funkcji jest ona większa lub równa $0$. W takim razie z twierdzenia 1. mamy:

\begin{eqnarray*}
I_n &=& \sum_{k=0}^n \frac{\langle f,T_k \rangle}{\langle T_k,T_k \rangle} \cdot T_k =\\ &=& \frac{2}{n+1}\sum_{k=0}^n' \langle f,T_k \rangle \cdot T_k  =\\ &=& \frac{2}{n+1}\sum_{k=0}^n'\left( \sum_{j=0}^nf(t_{n+1,j})T_k(t_{n+1,j})\right) \cdot T_k 
\end{eqnarray*}
\end{proof}
Przeprowadzając analogiczne do powyższego rozumowanie udowadnia się:

\begin{tw}
Wielomian $J_n$ n-tego stopnia interpolujący funkcję $f$ w ekstremach $T_n$ ma postać:
$$
J_n(x) = \frac{2}{n} \cdot \sum_{k=0}^n''\left( \sum_{j=0}^n'' f(u_{n,j})T_k(u_{n,j})\right)T_k(x)
$$
\end{tw}

\begin{tw}
Wielomian $K_n$ podany wzorem:
$$
K_n(x) = \frac{2}{n+1} \cdot \sum_{k=0}^n'\left( \sum_{j=0}^{n+1}'' f(u_{n+1,j})T_k(u_{n+1,j})\right)T_k(x)
$$
jest n-tym wielomianem optymalnym w sensie normy jednostajnej dla funkcji ciągłej f na zbiorze dyskretnym $U = \{u_{n+1,0},{u_{n+1,1},\ldots,u_{n+1,n+1}\}$.
\end{tw}

\begin{proof}
Z twierdzenia 2 wystarczy pokazać, że U jest alternansem. Niech $e(x) = f(x) - K_n(x)$. Zauważmy, że dla $x \in U \, \, f(x) = J_{n+1}(x)$. W takim razie dla $x \in U \, \, e(x) = J_{n+1}(x) - K_n(x)$. Dla $k = 0,1,\ldots,n+1$ mamy(dla skrócenia zapisu będziemy używać $u_k$ zamiast $u_{n+1,k}$):
\begin{eqnarray*}
e(u_k) &=& J_{n+1}(u_k) - K_n(u_k) = \frac{2}{n+1} \cdot \left[\frac{1}{2} \cdot \left( \sum_{j=0}^{n+1}'' f(u_j)T_{n+1}(u_j)\right)\right]T_{n+1}(u_k) =\\ &=& \frac{1}{n+1} \cdot \langle f,T_{n+1} \rangle T_{n+1}(u_k) = \frac{\langle f,T_{n+1} \rangle}{n+1} \cdot (-1)^k,
\end{eqnarray*} 
więc dla $k = 1,\ldots,n+1$ mamy $e(u_k) = -e(u_{k-1})$ oraz $|e(u_k)| = ||e||_\infty$ dla $k = 0,1,\ldots,n+1$, a z tego wynika, że U jest alternansem, co na mocy twierdzenia 2. pociąga za sobą tezę.
\end{proof}

\section{Aproksymacja}
Teraz zajmiemy się obliczaniem przybliżonego błędu aproksymacji jednostajnej funkcji przy użyciu $K_n,I_n,J_n$. Do obliczania wartości wielomianu zapisanego w bazie wielomianów Czebyszewa użyjemy algorytmu Clenshawa (\cite[strona 275]{Pas}). W załączonym programie \textit{program.jl} przeprowadzamy rachunki w następujący sposób: 

\begin{itemize}
\item Obliczanie $I_n(x)$: obliczamy współczynniki zewnętrznej sumy używając funkcji \textit{skalarf} - zwykły iloczyn skalarny. Następnie wykorzystując algorytm Clenshawa(funckja \textit{wielomianC}) obliczamy wartość wielomianu w $x$.

\item Obliczanie $J_n(x)$ i $K_n(x)$ można ulepszyć, gdyż korzystając z lematu 1. możemy wewnętrzne sumy również zapisać jako kombinację liniową wielomianów Czebyszewa, a więc dwukrotnie wykorzystamy tu algorytm Clenshawa.

\item Obliczanie przybliżonego błędu: dla każdego z wielomianów liczymy wartości błędu aproksymacji ($|f(x) - I_n(x)|,|f(x) - J_n(x)|,|f(x) - K_n(x)|$) w punktach $x_0,x_1,\ldots,x_{1000}$, gdzie $x_i = -1 + \frac{i}{1000}$ i spośród nich wybieramy największą wartość. 
\item Wszystkie obliczenia wykonujemy w arytmetyce DOUBLE.
\end{itemize} 

Obliczenia wykonamy dla funkcji
\begin{enumerate}
\item $f_1 = x^2 + \sin x$
\item $f_2 = x^4 \cdot \cos x$
\item $f_3 = \left( log(\sin x + 10) \right)^3$
\item $f_4 = \frac{x^2}{\sin(x)+1.1} \cdot e^x$
\end{enumerate}

oraz dla $n = 5,10,20,30,40,50$. Oznaczmy przez $e_I(f,n), e_J(f,n), e_K(f,n)$ odpowiednio znalezione przez nas największe wartości błędów aproksymacji odpowiednio wielomianami $I_n,J_n,K_n$ dla funkcji f.\footnote{Wykresy naszych wielomianów i aproksymowanych funkcji można zobaczyć na samym końcu załączonego programu \textit{program.jl}}\\

\begin{tabular}{|c|c|c|c|c|c|c|}
\hline 
$n$ & $e_I(f_1,n)$ & $e_J(f_1,n)$ & $e_K(f_1,n)$ & $e_I(f_2,n)$ & $e_J(f_2,n)$ & $e_K(f_2,n)$ \\ 
\hline 
5 & $6\cdot 10^{-6}$ & $6\cdot 10^{-6}$ & $6\cdot 10^{-6}$ & $1\cdot 10^{-2}$ & $3\cdot 10^{-2}$ & $1\cdot 10^{-2}$ \\ 
\hline 
10 & $2\cdot 10^{-11}$ & $5\cdot 10^{-11}$ & $2\cdot 10^{-11}$ & $2\cdot 10^{-8}$ & $2\cdot 10^{-8}$ & $2\cdot 10^{-8}$ \\ 
\hline 
20 & $7\cdot 10^{-11}$ & $1\cdot 10^{-15}$ & $1\cdot 10^{-15}$ & $1\cdot 10^{-11}$ & $1\cdot 10^{-15}$ & $1\cdot 10^{-15}$ \\ 
\hline 
30 & $1\cdot 10^{-6}$ & $1\cdot 10^{-15}$ & $1\cdot10^{-15}$ & $6\cdot 10^{-7}$ & $3\cdot 10^{-15}$ & $3\cdot 10^{-15}$ \\ 
\hline 
40 & $5\cdot 10^{-3}$ & $5\cdot 10^{-15}$ & $2\cdot 10^{-15}$ & $2\cdot 10^{-3}$ & $3\cdot 10^{-15}$ & $2\cdot 10^{-15}$ \\ 
\hline 
50 & $9\cdot 10^{0}$ & $1\cdot 10^{-15}$ & $2\cdot 10^{-15}$ & $2\cdot 10^{0}$ & $7\cdot 10^{-15}$ & $1\cdot 10^{-15}$ \\ 
\hline 
\end{tabular} \\

\begin{tabular}{|c|c|c|c|c|c|c|}
\hline 
$n$ & $e_I(f_3,n)$ & $e_J(f_3,n)$ & $e_K(f_3,n)$ & $e_I(f_4,n)$ & $e_J(f_4,n)$ & $e_K(f_4,n)$ \\ 
\hline 
5 & $1\cdot 10^{-5}$ & $3\cdot 10^{-5}$ & $2\cdot 10^{-5}$ & $6\cdot 10^{-3}$ & $8\cdot 10^{-3}$ & $4\cdot 10^{-3}$ \\ 
\hline 
10 & $5\cdot 10^{-10}$ & $6\cdot 10^{-10}$ & $4\cdot 10^{-10}$ & $3\cdot 10^{-5}$ & $4\cdot 10^{-5}$ & $2\cdot 10^{-5}$ \\ 
\hline 
20 & $5\cdot 10^{-10}$ & $9\cdot 10^{-14}$ & $6\cdot 10^{-14}$ & $7\cdot 10^{-10}$ & $7\cdot 10^{-10}$ & $4\cdot 10^{-10}$ \\ 
\hline
30 & $1\cdot 10^{-5}$ & $6\cdot 10^{-14}$ & $1\cdot 10^{-13}$ & $2\cdot 10^{-6}$ & $2\cdot 10^{-14}$ & $1\cdot 10^{-14}$ \\ 
\hline
40 & $6\cdot 10^{-2}$ & $1\cdot 10^{-13}$ & $1\cdot 10^{-13}$ & $7\cdot 10^{-3}$ & $1\cdot 10^{-14}$ & $9\cdot 10^{-15}$ \\ 
\hline 
50 & $7\cdot 10^{1}$ & $3\cdot 10^{-13}$ & $2\cdot 10^{-13}$ & $6\cdot 10^{1}$ & $9\cdot 10^{-15}$ & $1\cdot 10^{-14}$ \\ 
\hline 

\end{tabular}\\

Patrząc ma tabelki, możemy zauważyć,że:
\begin{itemize}
\item aproksymacja wielomianem $K_n$ osiąga przeważnie najmniejszą wartość błędu
\item aproksymacja $I_n$ dla $ n \geq 30$ jest nieskuteczna
\item błędy aproksymacji $K_n$ i $J_n$ maleją wraz ze wzrostem $n$ aż do $n \leq 30$, a dla większych $n$ nie zauważamy znaczącej poprawy wyniku
\item dla $n \geq 30$ aproksymacja zarówno $J_n$ jak i $K_n$ jest bardzo dobra, gdyż ich błędy są rzędu $10^{-13}$ albo nawet mniejszego
\item 
\end{itemize}\\

Nieskuteczność $I_n$ bierze się ze względu na numeryczne kłopoty podczas jego obliczania, a dokładnie z powodu funkcji \textit{skalarf} - standardowe obliczanie iloczyny skalarnego jest niestabilne ze względu na kumulujący się w czasie dodawania błąd - liczba tych operacji jest dość duża z powodu potrzeby obliczania wartości wielomianu Czebyszewa w punkcie za pomocą schematu Hornera. W algorytmie Clenshawa liczba tych operacji jest zdecydowanie mniejsza i zjawisko kumulacji błędu podczas dodawania nie ma takiego wpływu na wynik.  
 
	
\section{Podsumowanie}

Z przeprowadzonych obliczeń możemy wywnioskować ze wielomiany $I_n,J_n,K_n$ są bardzo dobrymi narzędziami do aproksymowania funkcji względem normy jednostajnej. Już dla $20$ punktów, a więc wielomianów $19$ stopnia, których obliczenie nie jest dla komputera żadnym wyzwaniem otrzymujemy bardzo dobre wyniki - przybliżony błąd jest dla testowanych przez nas funkcji rzędu nie większego niż $10^{-8}$. Wnioskujemy również, że ze względu na numeryczne własności lepiej nie stosować interpolacji $I_n$ ,mimo że zgonie z \cite[strony 105-106]{Bj} błąd ten powinien być najmniejszy ze wszystkich wielomianów interpolacyjnych tego samego stopnia(tzw. twierdzenie o optymalnym doborze węzłów). Stwierdzamy, że aproksymacja wielomianami $J_n$ i $K_n$ jest bardzo skuteczna, ale nie warto przesadzać ze stopniem znajdowanego przez nas wielomianu ze względu na brak poprawy wyniku dla $n \geq 30$. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{thebibliography}{9}
\itemsep2pt

\bibitem{JMJ} J. i M Jankowscy, Przegląd metod numerycznych część 1, Wydawnictwo Naukowo-Techniczne, Warszawa, 1988.

\bibitem{Pas} S. Paszkowski, Zastosowania numeryczne wielomianów i szeregów Czebyszewa, Państwowe Wydawnictwo Naukowe, Warszawa, 1975
            				
\bibitem{cos} Michael P. Knapp, Sines and Cosines of Angles in Arithmetic Progression, Loyola University Maryland, Baltimore, MD 21210-2699. \url{http://evergreen.loyola.edu/mpknapp/www/papers/knapp-sv.pdf}

\bibitem{Bj} Ake Bjorck, Germund Dahlquist, Metody numeryczne, Polskie Wydawnictwo Naukowe, Warszawa, 1987.
														
\end{thebibliography}
\end{document}
